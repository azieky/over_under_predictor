{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Gambling Statistics from ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/spreadspoke_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all rows not contains an Over/Under Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['over_under_line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the \"Game Spread\" to an Positive number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spread_favorite\"] = abs(df['spread_favorite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add \"Total\" column for the Total Amount of Points Scored in a given game. Using Away Points Score  + Home Points Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total'] = df['score_home'] + df['score_away'] \n",
    "# Change to an Interger\n",
    "df = df.astype({'total': 'int'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all Rows without an Over/Under Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.over_under_line != ' ']\n",
    "# Change to a Float\n",
    "df = df.astype({'over_under_line': 'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Target Variable, Over/Under Result Column\n",
    "* ##### 'Over' if the Total is greater than the Over/Under Line \n",
    "* ##### 'Under' if the Total is less than the Over/Under Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['over_under_result'] = np.where(df['total'] > df['over_under_line'], 'Over', 0)\n",
    "df['over_under_result'] = np.where(df['total'] == df['over_under_line'], np.nan, df['over_under_result'])\n",
    "df['over_under_result'] = np.where(df['total'] < df['over_under_line'], 'Under', df['over_under_result'])\n",
    "df = df.dropna(subset=['over_under_result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10052, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update 'Washington Redskins' team name, to 'Washington Football team'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_home'] = np.where(df['team_home'] == 'Washington Redskins', 'Washington Football Team', df['team_home'])\n",
    "df['team_away'] = np.where(df['team_away'] == 'Washington Redskins', 'Washington Football Team', df['team_away'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct all Alternative Names of Stadiums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stadium_name'] = df['stadium']\n",
    "df = df.drop(columns=['stadium'])\n",
    "\n",
    "# Create List of Stadium Names\n",
    "stadium_list = list(df['stadium_name'])\n",
    "\n",
    "# Create List of Hard Rock Stadium alternative stadium names\n",
    "hard_rock_stadium_alternates = ['Joe Robbie Stadium','Pro Player Stadium','Dolphin Stadium']\n",
    "\n",
    "# Create for loop that Changes all alternative name to 'Hard Rock Stadium'\n",
    "for i, stadium in enumerate(stadium_list):\n",
    "    if stadium in hard_rock_stadium_alternates:\n",
    "        stadium_list[i] = 'Hard Rock Stadium'\n",
    "        \n",
    "# Update Column Row with new stadium list with Hard Rock Stadium instead of Alternatives\n",
    "df['stadium_name'] = stadium_list\n",
    "\n",
    "# Change other independent events of Stadium name changes\n",
    "df['stadium_name'] = np.where(df['stadium_name'] == 'Tampa Stadium', 'Raymond James Stadium',df['stadium_name'])\n",
    "df['stadium_name'] = np.where(df['stadium_name'] == 'Alltel Stadium', 'TIAA Bank Field',df['stadium_name'])\n",
    "df['stadium_name'] = np.where(df['stadium_name'] == 'Jack Murphy Stadium', 'Qualcomm Stadium',df['stadium_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Stadium Data from ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium_df = pd.read_csv('data/nfl_stadiums.csv')\n",
    "\n",
    "# Merge Stadium Data to the Final DataFrame\n",
    "df = df.merge(stadium_df,on='stadium_name',how='left')\n",
    "\n",
    "#Drop Uneeded Columns\n",
    "df = df.drop(columns=['stadium_close','NAME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Stadium Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Add Stadium Locations\n",
    "df['stadium_location'] = np.where(df['stadium_name'] == 'FedEx Field', 'Landover, MD',df['stadium_location'])\n",
    "df['stadium_location'] = np.where(df['stadium_name'] == 'TIAA Bank Field', 'Jacksonville, FL',df['stadium_location'])\n",
    "\n",
    "# Drop all Nulls\n",
    "df = df.dropna(subset=['stadium_location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Games Played before 1978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.schedule_season > 1978]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct the Data the Stadium Opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FedEx Field         187\n",
       "TIAA Bank Field      17\n",
       "Rogers Centre         6\n",
       "Rose Bowl             4\n",
       "Alamo Dome            3\n",
       "Stanford Stadium      1\n",
       "Name: stadium_name, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['stadium_open'].isna()].stadium_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually change Open Years\n",
    "df['stadium_open'] = np.where(df['stadium_name'] == 'FedEx Field', 1997,df['stadium_open'])\n",
    "df['stadium_open'] = np.where(df['stadium_name'] == 'TIAA Bank Field', 1994,df['stadium_open'])\n",
    "df['stadium_open'] = np.where(df['stadium_name'] == 'Rose Bowl', 1921,df['stadium_open'])\n",
    "df['stadium_open'] = np.where(df['stadium_name'] == 'Alamo Dome', 1993,df['stadium_open'])\n",
    "df['stadium_open'] = np.where(df['stadium_name'] == 'Stanford Stadium', 1921,df['stadium_open'])\n",
    "\n",
    "df = df[df.stadium_name != 'Rogers Centre']\n",
    "\n",
    "# Change to Integer\n",
    "df = df.astype({'stadium_open': 'int'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix the Type of Stadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stadium_type'] = np.where(df['stadium_name'] == 'FedEx Field', 'outdoor',df['stadium_type'])\n",
    "df['stadium_type'] = np.where(df['stadium_name'] == 'TIAA Bank Field', 'outdoor',df['stadium_type'])\n",
    "df['stadium_type'] = np.where(df['stadium_name'] == 'Stanford Stadium', 'outdoor',df['stadium_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Zip Codes for all Stadiums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Zipcodes by splitting last 5 elements from Address Values\n",
    "df['zipcode'] = df['stadium_address'].str[-5:]\n",
    "\n",
    "# Adding Zip Codes to Stadiums Without Address\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'Rose Bowl', 91103,df['zipcode'])\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'Stanford Stadium', 94305,df['zipcode'])\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'FedEx Field', 20785,df['zipcode'])\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'TIAA Bank Field', 32202,df['zipcode'])\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'Mercedes-Benz Stadium', 30313,df['zipcode'])\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'SoFi Stadium', 90301,df['zipcode'])\n",
    "df['zipcode'] = np.where(df['stadium_name'] == 'Allegiant Stadium', 89118,df['zipcode'])\n",
    "\n",
    "# Drop Stadiums outside the U.S.\n",
    "df = df[df.stadium_name != 'Wembley Stadium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix the Surface Type for every Stadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change other names for Turf and Grass\n",
    "df['stadium_surface'] = np.where(df['stadium_surface'] == 'Hellas Matrix Turf', 'FieldTurf',df['stadium_surface'])\n",
    "df['stadium_surface'] = np.where(df['stadium_surface'] == 'Grass, Turf (1971-1974)', 'Grass',df['stadium_surface'])\n",
    "\n",
    "# Make corresponding list from the stadium name & stadium surface columns\n",
    "stadium_list = list(df['stadium_name'])\n",
    "surface_list = list(df['stadium_surface'])\n",
    "# Create list for All Stadiums with Turf Surfaces\n",
    "turf_stadiums = ['Giants Stadium','Texas Stadium','Hubert H. Humphrey Metrodome','RCA Dome','Veterans Stadium',\n",
    "                'Foxboro Stadium','Pontiac Silverdome','Three Rivers Stadium','Edward Jones Dome','Cinergy Field',\n",
    "                'Seattle Kingdome','Houston Astrodome','Busch Memorial Stadium','Mall of America Field',\n",
    "                'Husky Stadium',]\n",
    "# Create for loops to add Correct Surface for every Stadium in turf_stadium list\n",
    "for i, stadium in enumerate(stadium_list):\n",
    "    # Get the Index for the Stadium if the Stadium is in Turf Stadium List\n",
    "    if stadium in turf_stadiums:\n",
    "        surface_list[i] = 'FieldTurf'\n",
    "    # Use the index to change the corresponding Surface Type\n",
    "df['stadium_surface'] = surface_list\n",
    "\n",
    "# Change all the Stadiums that dont have Turf to Grass values\n",
    "df['stadium_surface'] = np.where(df['stadium_surface'] == 'FieldTurf', 'FieldTurf', 'Grass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ralph Wilson Stadium', 'Louisiana Superdome', 'Giants Stadium',\n",
       "       'Veterans Stadium', 'Seattle Kingdome', 'Busch Memorial Stadium',\n",
       "       'Foxboro Stadium', 'Pontiac Silverdome', 'Three Rivers Stadium',\n",
       "       'Cinergy Field', 'Texas Stadium', 'Houston Astrodome',\n",
       "       'Hubert H. Humphrey Metrodome', 'RCA Dome', 'Georgia Dome',\n",
       "       'Husky Stadium', 'Edward Jones Dome', 'M&T Bank Stadium',\n",
       "       'Paul Brown Stadium', 'Gillette Stadium', 'CenturyLink Field',\n",
       "       'Ford Field', 'Alamo Dome', 'Lucas Oil Stadium', 'Cowboys Stadium',\n",
       "       'Mall of America Field', 'MetLife Stadium',\n",
       "       'Mercedes-Benz Superdome', 'New Era Field', 'U.S. Bank Stadium',\n",
       "       'AT&T Stadium', 'Mercedes-Benz Stadium', 'SoFi Stadium'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['stadium_surface'] == 'FieldTurf']['stadium_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Stadium Capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Giants Stadium                   485\n",
       "Candlestick Park                 291\n",
       "Sun Life Stadium                 243\n",
       "Texas Stadium                    241\n",
       "Hubert H. Humphrey Metrodome     218\n",
       "Veterans Stadium                 193\n",
       "RCA Dome                         191\n",
       "FedEx Field                      187\n",
       "Foxboro Stadium                  180\n",
       "Pontiac Silverdome               177\n",
       "Mile High Stadium                176\n",
       "Three Rivers Stadium             175\n",
       "Edward Jones Dome                166\n",
       "Cinergy Field                    164\n",
       "Seattle Kingdome                 159\n",
       "Houlihan's Stadium               143\n",
       "Houston Astrodome                140\n",
       "RFK Memorial Stadium             138\n",
       "Cleveland Municipal Stadium      136\n",
       "Anaheim Stadium                  120\n",
       "Atlanta-Fulton County Stadium     94\n",
       "Busch Memorial Stadium            68\n",
       "Orange Bowl                       58\n",
       "Memorial Stadium (Baltimore)      51\n",
       "Sun Devil Stadium                 48\n",
       "Mall of America Field             38\n",
       "Metropolitan Stadium              23\n",
       "TCF Bank Stadium                  18\n",
       "Husky Stadium                     18\n",
       "TIAA Bank Field                   17\n",
       "Memorial Stadium (Champaign)      10\n",
       "Memorial Stadium (Clemson)         8\n",
       "Liberty Bowl Memorial Stadium      8\n",
       "Vanderbilt Stadium                 8\n",
       "Estadio Azteca                     4\n",
       "Tiger Stadium (LSU)                4\n",
       "Rose Bowl                          4\n",
       "Twickenham Stadium                 3\n",
       "Stanford Stadium                   1\n",
       "Name: stadium_name, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['stadium_capacity'].isna()].stadium_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually Import Each Stadium Capacity\n",
    "\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Giants Stadium',80242,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Candlestick Park',69732,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Sun Life Stadium',64767,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Texas Stadium',65675,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Hubert H. Humphrey Metrodome', 64121,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'RCA Dome',60567,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Veterans Stadium',65352,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'FedEx Field', 82000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Foxboro Stadium',60292,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Pontiac Silverdome',80311,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Mile High Stadium', 75000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Three Rivers Stadium',59000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Edward Jones Dome', 67277,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Cinergy Field', 59754,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Seattle Kingdome',66000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == \"Houlihan's Stadium\", 50000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Houston Astrodome', 65000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'RFK Memorial Stadium',45596,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Cleveland Municipal Stadium', 81000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Anaheim Stadium', 69008,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Atlanta-Fulton County Stadium', 60606,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Busch Memorial Stadium', 60000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Orange Bowl', 75000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Memorial Stadium (Baltimore)', 50000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Sun Devil Stadium', 53599,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Mall of America Field', 64121,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Metropolitan Stadium', 41200,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Wembley Stadium', 86000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Husky Stadium', 70000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'TCF Bank Stadium', 50805,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'TIAA Bank Field', 67814,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == \"Memorial Stadium (Champaign)\", 60670,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == \"Memorial Stadium (Clemson)\", 74000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Liberty Bowl Memorial Stadium', 58325,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Vanderbilt Stadium', 40550,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Rose Bowl', 92542,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == \"Tiger Stadium (LSU)\", 100000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Tulane Stadium', 70000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Stanford Stadium', 50000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Rice Stadium', 47000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Tulane Stadium', 70000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Stanford Stadium', 50000,df['stadium_capacity'])\n",
    "df['stadium_capacity'] = np.where(df['stadium_name'] == 'Rice Stadium', 47000,df['stadium_capacity'])\n",
    "\n",
    "# Take out comma's from the Stadium Capacity\n",
    "df['stadium_capacity'] = df.stadium_capacity.replace(',','', regex=True)\n",
    "\n",
    "df = df[df.stadium_name != 'Estadio Azteca']\n",
    "df = df[df.stadium_name != 'Twickenham Stadium']\n",
    "\n",
    "# Stadium Capacity to Integer\n",
    "df = df.astype({'stadium_capacity': 'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['stadium_capacity'].isna()].stadium_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Column for which Week of a Season a given game was played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 1-17 Regular Season Games\n",
    "# Week 18 and Above Playoff Games\n",
    "\n",
    "# Wildcard Playoff Games set as Week 18\n",
    "df['schedule_week'] = np.where(df['schedule_week'] == \"Wildcard\", 18,df['schedule_week'])\n",
    "df['schedule_week'] = np.where(df['schedule_week'] == \"WildCard\", 18,df['schedule_week'])\n",
    "# Divional Playoff Games set as Week 19\n",
    "df['schedule_week'] = np.where(df['schedule_week'] == 'Division', 19,df['schedule_week'])\n",
    "# Conference Championship Games set as Week 20\n",
    "df['schedule_week'] = np.where(df['schedule_week'] == 'Conference', 20,df['schedule_week'])\n",
    "# Superbowl Championship Games set as Week 21\n",
    "df['schedule_week'] = np.where(df['schedule_week'] == 'Superbowl', 21,df['schedule_week'])\n",
    "df['schedule_week'] = np.where(df['schedule_week'] == 'SuperBowl', 21,df['schedule_week'])\n",
    "\n",
    "# Change Week Number to Integers \n",
    "df = df.astype({'schedule_week': 'int'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Day of the Week a game was played "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the string to datetime format\n",
    "import datetime\n",
    "df['schedule_date'] = pd.to_datetime(df['schedule_date'])\n",
    "\n",
    "\n",
    "# Get Day of the Week Game was Played\n",
    "# 0 = Monday, \n",
    "# 1 = Tuesday\n",
    "# 2 = Wednesday\n",
    "# 3 = Thursday\n",
    "# 4 = Friday\n",
    "# 5 = Saturday\n",
    "# 6 = Sunday\n",
    "df['weekday'] = df['schedule_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Distance Between Home & Away Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with creating a column for Away Team Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an accurate Zipcode, get dataframe from early in the week & not a neutral stadium.\n",
    "early = df[(df.schedule_week < 4)&(df.stadium_neutral == False)]\n",
    "\n",
    "# Get a Dataframe of just the Teams and Their Corresponding Zipcodes\n",
    "zip_df = early[['team_home', 'zipcode']]\n",
    "\n",
    "\n",
    "# Change Column Names to use as Zipcode when Teams Away \n",
    "zip_df.columns = ['team_away','zipcode_away']\n",
    "\n",
    "# Drop Duplicates so Teams only have one Zipcode per Season\n",
    "zip_df = zip_df.drop_duplicates(subset = 'team_away')\n",
    "\n",
    "## Merge Away Zip Codes to Original Dataset ##\n",
    "df = df.merge(zip_df,how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Function to get distance between Two Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install The Needed Packages ##\n",
    "#!pip install uszipcode\n",
    "#!pip install mpu\n",
    "\n",
    "from uszipcode import SearchEngine\n",
    "import mpu\n",
    "\n",
    "# Zipcode Reader note Reading zipcode of Tempe,AZ so changed to Scottsdale,AZ\n",
    "df['zipcode'] = np.where(df['zipcode'] == '85287','85054',df['zipcode'])\n",
    "df['zipcode_away'] = np.where(df['zipcode_away'] == '85287','85054',df['zipcode_away'])\n",
    "\n",
    "# Instantiate Zip Code Reader\n",
    "search = SearchEngine(simple_zipcode=True)\n",
    "\n",
    "# Define Function that Takes two Zip Codes and Returns Distance between the Zip Codes\n",
    "def get_dist(zipcode_1,zipcode_2):\n",
    "    # Get Zip Code 1 Latitude and Longitude\n",
    "    zip1 = search.by_zipcode(zipcode_1)\n",
    "    lat1 = zip1.lat\n",
    "    long1 = zip1.lng\n",
    "    # Get Zip Code 2 Latitude and Longitude\n",
    "    zip2 = search.by_zipcode(zipcode_2)\n",
    "    lat2 = zip2.lat\n",
    "    long2 = zip2.lng\n",
    "    # Return Distance\n",
    "    return mpu.haversine_distance((lat1,long1),(lat2,long2))\n",
    "\n",
    "# Create Column Taking in the Zip Code of the Home Team and Zip Code of the Away Team. \n",
    "# Returning a column returning the distance between the Two Zip Codes\n",
    "df['dist_diff'] = df[['zipcode', 'zipcode_away']].apply(lambda x: get_dist(*x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Team Data from ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Webscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Scrape Settin Up Team Statistics Dataframe\n",
    "# URL to Pro Football Reference where there Data is located\n",
    "url = 'https://www.pro-football-reference.com/years/'+'1978'+'/'\n",
    "# Retrieve the First Dataframe containing AFC Conference Data\n",
    "afc_df = pd.read_html(url)[0]\n",
    "# Set the Year of the Season\n",
    "afc_df['Season_Year'] = '1978'\n",
    "# Retrieve the First Dataframe containing NFC Conference Data\n",
    "nfc_df = pd.read_html(url)[1]\n",
    "# Set the Year of the Season\n",
    "nfc_df['Season_Year'] = '1978'\n",
    "# Merge the Two Dataframes\n",
    "df_1 = [nfc_df,afc_df]\n",
    "team_df = pd.concat(df_1)\n",
    "team_df = team_df.reset_index(drop=True)\n",
    "# Delete Uneeded AFC and NFC Rows\n",
    "team_df = team_df[~team_df.Tm.str.contains(\"AFC\")]\n",
    "team_df = team_df[~team_df.Tm.str.contains(\"NFC\")]\n",
    "# Delete Uneeded Marks on Team Names\n",
    "team_df['Tm'] = team_df['Tm'].str.replace('+','')\n",
    "team_df['Tm'] = team_df['Tm'].str.replace('*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the Season needed to iterate through URL\n",
    "years = list(map(str,df.schedule_season.unique()))\n",
    "\n",
    "# Set up loop to retrieve all data for Needed Years(Seasons)\n",
    "for year in years:\n",
    "    # Set up url with corrisponding Year(Season) for the destination of the data\n",
    "    url = 'https://www.pro-football-reference.com/years/'+year+'/'\n",
    "    # get afc dataframe and add year\n",
    "    afc_df = pd.read_html(url)[0]\n",
    "    afc_df['Season_Year'] = year\n",
    "    # get nfc dataframe and add year\n",
    "    nfc_df = pd.read_html(url)[1]\n",
    "    nfc_df['Season_Year'] = year\n",
    "    # Combine dataframes\n",
    "    df_1 = [nfc_df,afc_df]\n",
    "    df_1 = pd.concat(df_1)\n",
    "    team_df = pd.merge(team_df, df_1,how = 'outer')\n",
    "    # Clean Master Dataframe\n",
    "    team_df = team_df.reset_index(drop=True)\n",
    "    team_df = team_df[~team_df.Tm.str.contains(\"AFC\")]\n",
    "    team_df = team_df[~team_df.Tm.str.contains(\"NFC\")]\n",
    "    team_df['Tm'] = team_df['Tm'].str.replace('+','')\n",
    "    team_df['Tm'] = team_df['Tm'].str.replace('*','')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update outdated NFL team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df['Tm'] = np.where(team_df['Tm'] == 'Washington Redskins', 'Washington Football Team',team_df['Tm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ready the Team Season data for Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert Columns to Float\n",
    "team_df[['W', 'L', 'T', 'W-L%', 'PF', 'PA', 'PD', 'MoV', 'SoS', 'SRS',\n",
    "       'OSRS', 'DSRS', 'Season_Year']] = team_df[['W', 'L', 'T', 'W-L%', 'PF', 'PA', 'PD', 'MoV', 'SoS', 'SRS',\n",
    "       'OSRS', 'DSRS', 'Season_Year']].astype(float)\n",
    "\n",
    "# Seperate Data into Two Dataframe for Home Team & Away Team\n",
    "home_team_df = team_df\n",
    "away_team_df = team_df\n",
    "\n",
    "# Add 1 to the Season Year because we are using previous season record\n",
    "home_team_df['schedule_season'] = home_team_df['Season_Year'] + 1 \n",
    "# No Value for Tied Games = 0\n",
    "home_team_df['T'] = home_team_df['T'].fillna(0)\n",
    "# Create a Points For per Games Column\n",
    "home_team_df['PF_per_game'] = home_team_df['PF']/(home_team_df['W'] + home_team_df['L'] + home_team_df['T'])\n",
    "# Create a Points Against per Games Column\n",
    "home_team_df['PA_per_game'] = home_team_df['PA']/(home_team_df['W'] + home_team_df['L'] + home_team_df['T'])\n",
    "# Drop Redundant Team Statistics\n",
    "home_team_df = home_team_df.drop(columns=['Season_Year', 'W', 'L', 'T','PF','PA'])\n",
    "\n",
    "# add 'home_' before all Home Team Columns\n",
    "col_names = list(home_team_df.columns)\n",
    "home_col_names = [\"home_\" + col for col in col_names]\n",
    "home_team_df.columns = home_col_names\n",
    "# Change 'home_tm' column name to corrispond with Final Dataset 'team_home'\n",
    "home_team_df['team_home'] = home_team_df['home_Tm']\n",
    "# Change 'home_schedule_season' column name to corrispond with Final Dataset 'schedule_season'\n",
    "home_team_df['schedule_season'] = home_team_df['home_schedule_season']\n",
    "# Drop Uneeded Columns\n",
    "home_team_df = home_team_df.drop(columns=['home_Tm','home_schedule_season'])\n",
    "\n",
    "# Left Merge Team Data to Final Dataframe. \n",
    "# Will merge on team_home and schedule_season\n",
    "final_df = df.merge(home_team_df,how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reiterate the Same process for Away Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_team_df['schedule_season'] = away_team_df['Season_Year'] + 1\n",
    "away_team_df['T'] = away_team_df['T'].fillna(0)\n",
    "away_team_df['PF_per_game'] = away_team_df['PF']/(away_team_df['W'] + away_team_df['L'] + away_team_df['T'])\n",
    "away_team_df['PA_per_game'] = away_team_df['PA']/(away_team_df['W'] + away_team_df['L'] + away_team_df['T'])\n",
    "away_team_df = away_team_df.drop(columns=['Season_Year', 'W', 'L', 'T','PF','PA'])\n",
    "\n",
    "col_names = list(away_team_df.columns)\n",
    "away_col_names = [\"away_\" + col for col in col_names]\n",
    "away_team_df.columns = away_col_names\n",
    "away_team_df['team_away'] = away_team_df['away_Tm']\n",
    "away_team_df['schedule_season'] = away_team_df['away_schedule_season']\n",
    "away_team_df = away_team_df.drop(columns=['away_Tm','away_schedule_season'])\n",
    "\n",
    "final_df = final_df.merge(away_team_df,how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop All null values for team names that didnt match Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.dropna(subset=['home_W-L%'])\n",
    "final_df = final_df.dropna(subset=['away_W-L%'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Preseason Superbowl Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Webscraper to retrieve Preseason Superbowl Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url with the destination of the Needed Data\n",
    "url = \"https://www.pro-football-reference.com/years/2020/preseason_odds.htm#preseason_odds::none\"\n",
    "# Set up the Orginial Dataframe with 2020 Preseason Superbowl Odds\n",
    "superbowl_odds = pd.read_html(url)[0]\n",
    "superbowl_odds['Season_Year'] = '2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the years list to determine the data retrieved \n",
    "for year in years:\n",
    "    url = \"https://www.pro-football-reference.com/years/\"+year+\"/preseason_odds.htm\"\n",
    "    superbowl_odds_1 = pd.read_html(url)[0]\n",
    "    superbowl_odds_1['Season_Year'] = year\n",
    "    # Merge Superbowl Odds to original Superbowl Odds dataset\n",
    "    superbowl_odds = pd.merge(superbowl_odds, superbowl_odds_1,how = 'outer')\n",
    "\n",
    "# Drop Uneeded Columns\n",
    "superbowl_odds_df = superbowl_odds.drop(columns=['W/L O-U','Record'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix outdated team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "superbowl_odds_df['Tm'] = np.where(superbowl_odds_df['Tm'] == 'Washington Redskins', 'Washington Football Team',superbowl_odds_df['Tm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seperate dataframe into two matching Away Team and Home Team dataframs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change schedule_season to an integer to match dataframes\n",
    "superbowl_odds_df[['Season_Year']] = superbowl_odds_df[['Season_Year']].astype(float)\n",
    "\n",
    "# Split to Home and Away Teams\n",
    "home_superbowl_odds_df = superbowl_odds_df\n",
    "away_superbowl_odds_df = superbowl_odds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Superbowl Data to Merge into Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change home team column names to match Final Dataframe Column names\n",
    "home_superbowl_odds_df.columns = ['team_home', 'home_superbowl_odds','schedule_season']\n",
    "# Left Merge match team_home and 'schedule_season'\n",
    "final_df = final_df.merge(home_superbowl_odds_df,how='left')\n",
    "\n",
    "# Reiterate Process for the Away Team\n",
    "away_superbowl_odds_df.columns = ['team_away', 'away_superbowl_odds','schedule_season']\n",
    "final_df = final_df.merge(away_superbowl_odds_df,how='left')\n",
    "\n",
    "# Will Amend if there is Time, For now drop 2020 data\n",
    "final_df = final_df.dropna(subset=['home_superbowl_odds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Differences of Team Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets differnce in Team Data Statistics\n",
    "final_df['diff_W-L%'] = abs(final_df['home_W-L%'] - final_df['away_W-L%'])\n",
    "final_df['diff_PD'] = abs(final_df['home_PD']- final_df['away_PD'])\n",
    "final_df['diff_MoV'] = abs(final_df['home_MoV']- final_df['away_MoV'])\n",
    "final_df['diff_SoS'] = abs(final_df['home_SoS']- final_df['away_SoS'])\n",
    "final_df['diff_SRS'] = abs(final_df['home_SRS']- final_df['away_SRS'])\n",
    "final_df['diff_OSRS'] = abs(final_df['home_OSRS']- final_df['away_OSRS'])\n",
    "final_df['diff_PF_per_game'] = abs(final_df['home_PF_per_game']- final_df['away_PF_per_game'])\n",
    "final_df['diff_PA_per_game'] = abs(final_df['home_PA_per_game']- final_df['away_PA_per_game'])\n",
    "final_df['diff_superbowl_odds'] = abs(final_df['home_superbowl_odds']- final_df['away_superbowl_odds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('data/final_df.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Over', 'Under'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.over_under_result.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
